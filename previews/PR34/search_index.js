var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = BayesianQuadrature","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Models","page":"API","title":"Models","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"BayesianModel","category":"page"},{"location":"api/#Samplers","page":"API","title":"Samplers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"PriorSampling","category":"page"},{"location":"api/#BayesianQuadrature.PriorSampling","page":"API","title":"BayesianQuadrature.PriorSampling","text":"PriorSampling()\n\nSampler which will use the prior distribution from the given model to provide samples.\n\n\n\n\n\n","category":"type"},{"location":"api/#Bayesian-Quadratures","page":"API","title":"Bayesian Quadratures","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"BayesQuad","category":"page"},{"location":"api/#BayesianQuadrature.BayesQuad","page":"API","title":"BayesianQuadrature.BayesQuad","text":"BayesQuad(k::Kernel; l=1.0, Ïƒ::Real=1.0)\n\nBayesian Quadrature object. You can pass any kernel and the lengthscale and variance will be extracted. l can be a Real, a AbstractVector or a LowerTriangular.\n\n\n\n\n\n","category":"type"},{"location":"theory/#Theory","page":"Theory","title":"Theory","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"note: Note\nThis is a very quick and dirty introduction to Bayesian quadrature. For a more concrete introduction, see these nice slides","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Bayesian Quadrature is a probabilistic numerics methods to compute integrals. The idea is to compute the integral","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"I = int f(x) p(x)dx","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"where p(x)sim mathcalN, by representing the function f(x) by a Gaussian Process.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"However, to know what the posterior of f is like, we need samples x_i y_i where y_i = f(x_i) + epsilon, with epsilon being some noise. In the end, instead of looking for an approximation of I, we obtain a posterior distribution for it values:","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"    p(Ix_iy_i) = mathcalN(mu sigma^2)","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Under some conditions, the mean mu and the variance sigma^2 can be found analytically.","category":"page"},{"location":"userguide/#User-guide","page":"User Guide","title":"User guide","text":"","category":"section"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"To run Bayesian quadrature multiple ingredients are needed:","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"The model, containing the integrand function f and the prior p_0\nThe sampling process, the algorithm choosing the samples x_i y_i used to estimate the integral\nThe Bayesian quadrature algorithm, containing both the kernel and the way the posterior of the integral is computed ","category":"page"},{"location":"userguide/#The-model","page":"User Guide","title":"The model","text":"","category":"section"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"So far only one model is implemented: the BayesModel. It takes a MvNormal prior and a log-likelihood function, in the future more options for the prior will be available using importance re-weighting! In Bayesian terms, given the data y and latent parameters theta, with given likelihood p(ytheta) and prior p_0(theta), we are interested in the evidence p(y) = int p(ytheta)p_0(theta)dtheta. One needs to pass p_0::MvNormal equiv p_0 and loglike(theta) = logpdf(likelihood(theta), y) equiv log p(ytheta)   ","category":"page"},{"location":"userguide/#The-sampling-process","page":"User Guide","title":"The sampling process","text":"","category":"section"},{"location":"userguide/#The-Bayesian-quadrature-algorithm","page":"User Guide","title":"The Bayesian quadrature algorithm","text":"","category":"section"},{"location":"#BayesianQuadrature","page":"Home","title":"BayesianQuadrature","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for the Bayesian quadrature package for Julia.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For an explanation of what Bayesian quadrature is, see Theory.\nFor a description of the different elements that one can play with, see the User guide\nFor the API of each element, see the API page","category":"page"}]
}
